# ==============================================================================
# QUAN TÂM CHÍNH: LƯỢNG TỬ, AI, VỆ TINH & MẠNG 6G
# ==============================================================================

# --- 1. LƯỢNG TỬ & MẠNG TRÊN KHÔNG (Quantum + Satellite/Aerial Networks) ---
quantum+satellite
quantum+NTN
quantum+SAGINs
"quantum communication"+satellite
"quantum network"+satellite
"quantum key distribution"+satellite
QKD+satellite
"quantum computing"+space
"satellite quantum"
"quantum sensing"+satellite
"aerial quantum"

# --- 2. AI & MẠNG TRÊN KHÔNG (AI + Satellite/Aerial Networks) ---
AI+satellite
"Artificial Intelligence"+satellite
"machine learning"+satellite
"deep learning"+satellite
AI+NTN
AI+SAGINs
"reinforcement learning"+satellite
"federated learning"+satellite
"AI for NTN"
"AI for SAGINs"
"satellite imagery"+AI
"satellite communication"+AI

# --- 3. MẠNG 6G & CÁC CÔNG NGHỆ LIÊN QUAN ---
6G
"6G network"
"6G communication"
"beyond 5G"
B5G
"terahertz communication"
THz
"intelligent reflecting surface"
IRS
RIS
"reconfigurable intelligent surface"
"cell-free massive MIMO"
"holographic radio"
"integrated sensing and communication"
ISAC
"semantic communication"
"age of information"
AoI
"network slicing"+6G

# ==============================================================================
# QUAN TÂM PHỤ: FEDERATED LEARNING & KIẾN TRÚC AI
# ==============================================================================

# --- 4. FEDERATED LEARNING (HỌC TẬP LIÊN BANG) ---
"federated learning"
FL
"federated optimization"
"federated averaging"
FedAvg
"personalized federated learning"
"asynchronous federated learning"
"hierarchical federated learning"
"decentralized federated learning"
"split learning"

# --- 5. KIẾN TRÚC AI & MÔ HÌNH NỀN TẢNG (AI Architectures & Foundation Models) ---
Transformer
"attention mechanism"
"large language model"
LLM
"foundation model"
"vision transformer"
ViT
"generative adversarial network"
GAN
"diffusion model"
"graph neural network"
GNN
"neural architecture search"
NAS
"mixture of experts"
MoE
"model compression"
"model quantization"
"parameter-efficient fine-tuning"
PEFT
LoRA
